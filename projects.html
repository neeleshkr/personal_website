<!DOCTYPE html>
<html>

<head>
  <title>Neelesh R. Projects</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/base/jquery-ui.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/widgets.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/widgets.js"></script>
  <script src="js/custom.js"></script>
  <style>
    .menu-projects {
      color: rgba(255, 255, 255, 1) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }

    * {box-sizing: border-box}
    body {font-family: Verdana, sans-serif; margin:0}
    .mySlides {display: none}
    img {vertical-align: middle;}

    /* Slideshow container */
    .slideshow-container {
      max-width: 1000px;
      position: relative;
      margin: auto;
    }

    /* Hide the images by default */
    .mySlides {
      display: none;
    }

    .row {
      display: flex;
    }

    .column {
      flex: 50%;
      padding: 10px;
    }

    /* Next & previous buttons */
    .slidesPrev, .slidesNext {
      cursor: pointer;
      position: absolute;
      top: 50%;
      width: auto;
      margin-top: -22px;
      padding: 16px;
      color: white;
      font-weight: bold;
      font-size: 24px;
      transition: 0.6s ease;
      border-radius: 0 3px 3px 0;
      user-select: none;
    }

    /* Position the "next button" to the right */
    .slidesNext {
      right: 0;
      border-radius: 3px 0 0 3px;
    }

    /* On hover, add a black background color with a little bit see-through */
    .slidesPrev:hover, .slidesNext:hover {
      background-color: rgba(0,0,0,0.8);
      color: white;
    }

    /* Caption text */
    .caption-container {
      text-align: center;
      background-color: #0c053b;
      padding: 2px 16px;
      color: white;
    }

    /* The dots/bullets/indicators */
    .slidesDot {
      cursor: pointer;
      height: 15px;
      width: 15px;
      margin: 0 2px;
      background-color: #9dabbd;
      border-radius: 50%;
      display: inline-block;
      transition: background-color 0.3s ease;
    }

    .slidesDot:hover {
      background-color: #476894;
    }

    .slidesDot.active {
      background-color: #1f4980;
    }

    /* Fading animation */
    .fade {
      -webkit-animation-name: fade;
      -webkit-animation-duration: 1s;
      animation-name: fade;
      animation-duration: 1s;
    }

    @-webkit-keyframes fade {
      from {opacity: .6}
      to {opacity: 1}
    }

    @keyframes fade {
      from {opacity: .6}
      to {opacity: 1}
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
      	<div class="flex-row">
          <h1 class="add-top-margin">Student Organizations</h1>
	        <div class="flex-item flex-column">
    				<h2 class="add-top-margin">Berkeley Formula Racing (Co-Lead: Su19-Sp20, Member: Fa18-Sp19)</h2>
            <a class="anchor" id="bfr"></a>
    				<hr>
    				<p class="text">
              <img class="image image-wrap-text max-width-400" src="img/BFRCarCloseup.jpg" style="width:300px;margin-left:0px;margin-right:20px;margin-top:10px;margin-bottom:10px;">
    					<u>Intro:</u> I spent 2 very exciting, fast-paced years with the <a href="https://fsae.berkeley.edu/" target="_blank">Berkeley Formula Racing</a> Team, most recently as Electrical Subsystem Co-Lead. In this organization, students design, build, and race a fully functional Formula-1 style racecar to complete in the annual <a href="https://www.sae.org/attend/student-events" target="_blank">Formula SAE competition</a>. I worked with about 60 remarkably dedicated fellow students with a similar passion for fast cars. We all spent over 20 hours a week on the car! My first year, our team placed 16th place overall out of over 80 competitive college teams; our second year, we couldn't compete in person due to COVID-19 üòî.
              <br> <br>
              <u>Projects:</u> Electrical's design season is spent on projects to further the performance of the car, such as PCB designing, live-telemetry for data acquisition in real-time, a board and casing to house the 6-axis accelerometer and gyroscope, and a dash PCB for shifting lights to indicate the ideal time to shift gears based on a torque-power mapping. For example, I significantly optimized the design and performance of a board called the Brake Plausibility Device (BPD). The board had to shut off the car in the event of a critical failure to protect the driver. For example, suppose that while running the car, a rock got lodged in the throttle, keeping it open at all times. Then, even if the driver pressed the brakes, they wouldn't be able to stop; the BPD had to contain the logic to detect that something must be wrong in such situations and shut off power to the car. This functionality was achieved with transistor-based logic.
            </p>
            <div class="row">
              <div class="column">
                <img class="image max-width-400" src="img/BFRSittingInCar.JPG" style="width:100%;">
                <p class="image-caption">Me sitting in our B19 competition car!</p>
              </div>
              <div class="column">
                <img class="image max-width-400" src="img/BFRCCarWiring.jpg" style="width:100%;">
                <p class="image-caption">Closeup of the final racecar.</p>
              </div>
            </div>
            <p class="text20px">
              <u>Manufacturing:</u> Another primary responsiblity of Electrical is to ensure the mechanical robustness of the 3 primary wire harnesses; Power (ensure all components are powered), ECU (Engine Control Unit), and ADL (sensor data collection). By modularizing the harness bundle into 3 components, we made it much easier to debug and place on the car. As an example, a high-level design for our power harness can be found <a href="project_materials/PowerHarnessDiagramB20.pdf" target="_blank">here</a>. We also placed labels on each wire to avoid time-consuming multimeter continuity checks, easily saving several dozen man-hours over the years. A large amount of our production time is spent on these harnesses; ordering materials, manufacturing, placing the harnesses on the car, and debugging as issues come up in testing.
            </p>
          </div>
    			<div class="flex-item flex-column">
    				<h2 class="add-top-margin">IEEE Professional Development (Director: Su19-Fa19, Officer: Fa18-Sp19)</h2>
            <a class="anchor" id="ieee"></a>
    				<hr>
            <img class="image image-wrap-text max-width-400" src="img/BFRCarWiring.jpg" style="width:600px;margin-left:0px;margin-right:20px;margin-top:10px;margin-bottom:10px;">
    				<p class="text">
    					Elected as Director of the Professional Development Committee for UC Berkeley's <a href="https://ieee.berkeley.edu/" target="_blank">IEEE Student Branch</a>, I helped organize over 20 events and originated many new event ideas. The events spanned from Research Meet-and-Greets to help undergraduates engage with research to Technical Writing and Personal Website Design Workshops to build communication skills and a professional brand. Each event required weeks of planning, especially to ensure that we had representatives from industry or research labs, as well as support from IEEE's members for staffing.
            </p>
            <p class="text">
              IEEE introduced me to some of the brightest minds on campus, ensuring that I had a place to ask informed questions about classes and Berkeley life. It's been great to hear about the amazing research and activities people are engaged in, and I've been able to give some of this advice back as an IEEE mentor in recent semesters.
    				</p>
    			</div>
        </div>
        <div class="flex-row">
          <h1 class="add-top-margin">Class Projects</h1>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">NMOS Device Design</h2>
            <hr>
            <p class="text">
              In my EE 130 device design class, I used TCAD (Sentaurus Workbench) to numerically simulate the behavior of the custom-designed NMOS device. The channel length was specified at 25 nm based on the current 20 nm CMOS generation. The goal for this project was to become more familiar with how real-world transistors are designed, keeping specifications and tradeoffs in mind. We want to maximize active (on) current and decrease leakage (off) current. As an example, decreasing channel doping causes drain-induced barrier lowering (DIBL), leading to greater leakage current, but increases on-current (higher mobility, less ion-scattering). I explored the effects of such parameters and extracted useful information from the software‚Äôs simulation capabilities in order to optimize current consumption (I<sub>on</sub> and I<sub>off</sub>), subthreshold swing, and transconductance. I furthermore used my knowledge of device physics to explain what implications a certain design decision would have, and the rationale behind my choices. As can be expected, most design parameters presented a tradeoff, and they interacted with each other in complex ways.
            </p>
            <p class="text">
              The software self-consistently solves the electrostatics equations for a given set of device parameters to numerically determine the current at different applied gate and drain voltages. It also constructs images of device layouts for visualization purposes. The parameters experimented with include channel doping, source/drain extension depths, various dopant concentrations, the gate-dielectric spacer length, and others. By optimizing the parameters, I achieved an I_<sub>on</sub> to I_<sub>off</sub> ratio of 1.04 * 10<sup>18</sup>, 21 times better than the default value. Please <a rel="noopener noreferrer" target="_blank" href="mailto:neelesh.r@berkeley.edu">email me</a> for a copy of the full report, including tables and figures outlining my findings such as the sample ones below.
            </p>
          </div>
          <p class="text text-center graph-title no-top-margin" style="margin-left:auto;margin-right:auto;">
            Data from Experiments Run with Varying Dielectric Spacer Length L<sub>sp</sub>. Default Shown in Red.
          </p>
          <img class="image center" src="img/Lsp_table.PNG" style="width:600px;margin-left:auto;margin-right:auto;">
          <p class="text text-center graph-title no-top-margin" style="margin-left:auto;margin-right:auto;">
            Graph of Current Consuption at Varying Dielectic Spacer Lengths (note I<sub>on</sub> and I<sub>off</sub> tradeoff).
          </p>
          <img class="image center" src="img/Lsp_graph.PNG" style="width:600px;margin-left:auto;margin-right:auto;">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">BJT/MOS Amplifier Designs</h2>
            <hr>
            <p class="text">
              For my EE 105 class, our final labs consisted of single-stage BJT and MOS amplifier designs. In the preliminary labs, we characterized device behavior for a diode and BJT using a Semiconductor Parameter Analyzer (Agilent 4155C), connecting our experimentally observed curves to the physics behind them. We used SpaZilla, a Labview program, for instrument control and data acquisition. One of the important tasks at this stage was characterizing the capacitances; there was parasitic capacitance (from the breadboard and equipment) and component capacitance. By noting that these capacitances are in parallel, we could measure the cutoff frequency for different bias voltages, construct a graph, and linearly extrapolate the zero-bias capacitance.
            </p>
            <p class="text">
              Once we learned about DC biasing of transistors using resistive voltage dividers, we constructed amplifier circuits and measured performance with varying component values, experimentally and in simulation (LTspice). Figuring out a way to bias the circuits to maintain a temperature-independent bias point was challenging, but with practice, biasing and analyzing transistor-based circuit configurations became much more intuitive.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Cooke Triplet Optical Device Optimization</h2>
            <a class="anchor" id="ee118-cooke-triplet"></a>
            <hr>
            <p class="text">
              A Cooke Triplet is a 3-lens configuration that, when designed well, can entirely remove second-order aberrations (monochromatic and chromatic both) and function as an effective imaging device. However, each lens has two surfaces which can have varying radii of curvature and can be made of different materials, and the lenses have distances between them, so there are many variables involved.
            </p>
            <p class="text">
              In my EE 118 Final Project, we used Zemax Optical Studio for our analysis of the Cooke Triplet, and observed ray fan plots, spot diagrams, vignetting diagrams, and more to optimize the system. We also analyzed the parameter tolerances to gauge the most important variables (that is, which variables were most sensitive, and had to be given highest fine-tuning priority). For more details about the tools used and the design process, please see our presentation below (or in a <a href="project_materials/CookeTripletPresentation.pdf" target="_blank">new tab</a>) and our <a href="project_materials/CookeTripletFinalReport.pdf" target="_blank">final report</a>.
            </p>
              <embed src="project_materials/CookeTripletPresentation.pdf" type="application/pdf" width="100%" height="550px" />
            <p>
          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Avatar-Based Maze Game</h2>
            <a class="anchor" id="cs61b-avatar-game"></a>
            <hr>
            <p class="text">
              Our final CS 61B project was to create a game; the core constraints were that the tile-based environment must be (pseduo-)randomly generated, and for extra credit, there must be some kind of avatar that is user controlled, and there must be a way to "win" or complete the game. We took these concepts and built a remarkably intricate game that we and friends genuinely enjoyed playing, beyond just for the class. The gameplay was as follows (taken directly from our "folklore/background" section of the project):
            </p>
            <p class="text">
              The goal of the game is as follows: you control an avatar, the white star. It's tiny, but persistent. By using the WASD keys to move around, you can avoid the menacing exclamation marks (!) following you around. You may be steadfast in your willingness to get to the end point, but they're equally motivated to make sure that never happens. You ultimately want to get to the yellow locked door (multiple times!) to win the game and attain absolute glory. Be careful, there are some specific rules to follow. Once you traverse a tile, it becomes more red, and eventually, it'll become a deadly lava tile, indicated by the presence of an emoji! If you go over a lava tile, you lose a life (you have 3 total to begin with). If the (!) hits you, you lose a life. Try and collect flowers! They're on your side; the less health you have, the more likely they are to help you and grant a life. Each turn, you also have a chance to generate new flowers! Don't worry about running out üòÑ
            </p>
            <p class="text">
              As a user, you can toggle the wall color scheme, see an interesting bit of background for the game, toggle a super-hard mode, and customize your gameplay. As a programmer, you can do so much more; alter the room-generation algorithm to make easer/harder maps, modify the enemy behavior, change the spawn frequency and helpfulness of flowers; the list is endless. Take a look below for an idea of how the game looks!
            </p>
            <div class="slideshow-container">
            <!-- Full-width images with number and caption text -->
              <div class="mySlides fade">
                <img src="img/cs61b_home.png" style="width:100%">
              </div>
              <div class="caption-container">
                <p class="slidesCaption">Home page</p>
              </div>

              <div class="mySlides fade">
                <img src="img/cs61b_startsample2.png" style="width:100%">
              </div>
              <div class="caption-container">
                <p class="slidesCaption">Starting world, with super-color mode toggled on.</p>
              </div>

              <div class="mySlides fade">
                <img src="img/cs61b_startsample_nocolor.png" style="width:100%">
              </div>
              <div class="caption-container">
                <p class="slidesCaption">A not-so-colorful starting world (color mode toggled off).</p>
              </div>

              <div class="mySlides fade">
                <img src="img/cs61b_lavatrail.png" style="width:100%">
              </div>
              <div class="caption-container">
                <p class="slidesCaption">Creating a trail of lava tiles behind me in the top-right corner (not so smart!)</p>
              </div>

              <div class="mySlides fade">
                <img src="img/cs61b_unlockeddoor1.png" style="width:100%">
              </div>
              <div class="caption-container">
                <p class="slidesCaption">Unlocking a door makes the world darker, with a torchlight-effect around the avatar.</p>
              </div>

              <div class="mySlides fade">
                <video preload controls playsinline class="image">
                  <source src="vid/cs61b_samplevideo.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="caption-container">
                <p class="slidesCaption">Sample video of start menu, folklore, music, and a successful win!</p>
              </div>

              <!-- Next and previous buttons -->
              <a class="slidesPrev" onclick="plusSlides(-1)">&#10094;</a>
              <a class="slidesNext" onclick="plusSlides(1)">&#10095;</a>

            </div>
          <br>

          <!-- The dots/circles -->
          <div style="text-align:center">
            <span class="slidesDot" onclick="currentSlide(1)"></span>
            <span class="slidesDot" onclick="currentSlide(2)"></span>
            <span class="slidesDot" onclick="currentSlide(3)"></span>
            <span class="slidesDot" onclick="currentSlide(4)"></span>
            <span class="slidesDot" onclick="currentSlide(5)"></span>
            <span class="slidesDot" onclick="currentSlide(6)"></span>
          </div>

          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Voice-Controlled Robot Car</h2>
            <a class="anchor" id="ee16b-robot-car"></a>
            <hr>
            <p class="text">
              The goal of this semester-long project was to use linear algebra and circuits principles to build a car that could respond to a constrained set of voice commands, and perform actions based on what was spoken. A microphone collected the audio, which was processed by the on-car low-power Launchpad microcontroller board. Once the audio was filtered and processed, it was then classified as one of 4 words; the selected word determined the action the car took. We applied close-loop feedback to ensure that the car moved as intended with steady-state error correction; with open-loop feedback, the car did not move smoothly.
            </p>
            <p class="text">
              Our microphone circuitry consisted of a band-pass filter (low-pass chained to a high-pass) to isolate frequencies outside normal human speech. The signal was level-shifted and gained up by an amplifier, with noise and signal drift removed by a decoupling capacitor. It took over 40 voice recordings to find 4 viable words ("moose," "blob," "oscillate," "multiplicity") that the PCA classification could achieve high accuracy with. Yes, we're aware that in a practical setting, you perhaps wouldn't want to say "blob" to make a car go forward üòâ. For many other word combinations, two or more of the resulting k-means clusters would be too close together, and results were muddled. But in the end, our Integration checkoff went smoothly, as our car responded correctly to all of the given commands! Granted, there was some shouting and repetition but overall, definitely a success.
            </p>
          </div>
        </div>
        <div class="flex-row">
          <h1 class="add-top-margin">Other Projects</h1>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">CalHacks 6.0: Sign-ify iOS app (<a href="https://devpost.com/software/voice-to-asl-for-enhanced-education-through-webcasts" target="_blank">Best Weights and Biases API Prize</a>) (Nov. 2019)</h2>
            <a class="anchor" id="signify"></a>
            <hr>
            <p class="text">
              <img class="image image-wrap-text max-width-400" src="img/signifyLogo.jpg" style="width:500px;margin-left:auto;margin-right:auto;">
              I've always been interested in teaching, and after coming to Berkeley, I have become more aware of the importance of creating an inclusive environment for everyone to learn. Imposter syndrome runs rampant, and it's our job as a community to ensure everybody is comfortable exercising their opinion and doing whatever they need to learn best, be it asking questions during lecture, turning to a friend for help, or reviewing past lecture materials. In this 36-hour hackathon, we focused on the underserved community of deaf or hard-of-hearing students, who communicate, understand, and think primarily in ASL. The majority of deaf people do not have an ‚Äúinner voice‚Äù; instead they often <a href="http://www.sciencedaily.com/releases/2011/03/110322105438.htm" target="_blank">sign ASL in their heads</a> to themselves. For this reason, deaf students are largely disadvantaged in academia, especially with regard to live attendance of lectures. Our app enables enhanced live-lecture for members of the ASL-speaking community by intelligently converting the professor's speech to a sequence of ASL videos for the user to watch during lecture. This style of real-time audio to ASL conversion has never been done before, and our app bridges the educational barrier that exists in the deaf and hard-of-hearing community.
            </p>

            <p class="text">
              We broke down the development of the app into 3 phases: converting voice to speech, converting speech to ASL videos, and connecting the two components together in an iOS application. Building off of existing on-device speech recognition models including Pocketsphinx, Mozilla DeepSpeech, iOS Dictation, and more, we decided to combine them in an ensemble model. We employed the Google Cloud Speech to Text API to transcribe videos for ground truth, against which we compared transcription error rates for our models by phonemes, lengths, and syllabic features. Finally, we ran our own tests to ensure that the speech-to-text API was dynamically editing previously spoken words and phrases using context of neighboring words. The ideal weights for each weight assigned to each candidate were optimized over many iterations of testing using the Weights & Biases API (along with generous amounts of freezing layers and honing in!).
            </p>
            <p class="text">
              As a team we were most proud of our ability to quickly learn new frameworks and use Machine Learning and Reinforcement Learning to develop an application that was scalable and modular. While we were subject to a time restriction, we ensured that our user interface was polished, and that our final app integrated several frameworks seamlessly to deliver a usable product. We pushed ourselves to learn unfamiliar skills so that our solution would be comprehensive, and of course, we‚Äôre proud of our ability to come together and solve a problem that could benefit an entire community.
            </p>
          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Ascend x Travonde Case Competition (1st Place) (Oct. 2019)</h2>
            <a class="anchor" id="ascend-swe-challenge"></a>
            <hr>
            <p class="text">
              <img class="image image-wrap-text max-width-400" src="img/AscendWinnersPhoto.jpg" style="width:350px;margin-left:20px;margin-right:20px;">
              We went through 2 elimination rounds, each with a presentation and judge Q&A. At the end, once we were named as the first place winners, we met and talked with Steve Wozniak! <br> <br>
              Here's a condensed summary of our final report: For the Ascend x Travonde Software Engineering challenge, our goal was to optimize the engagement that members of the older-adult community have. After extensive market analysis, we realized that there is a significant dearth of opportunities for older people to form deeper interpersonal connections. This is partly because of the rapid advent of new technological frameworks. So, we developed a multifunctional tool to facilitate this process. Here‚Äôs how it works: our registration survey collects logistical and personality information from those interested in connecting to other locals. Then, we process the data using a performant matching algorithm and make an informal introduction through our chat interface suggesting some curated and personalized activities for an initial gathering.
            </p>
            <p class="text">
              Our product is presented in the form of a sleek, elegant workflow modeled with a web interface, showcasing how a user might fill out their profile and what features we would consider while matching. Once we match them with another user, we would initiate a conversation between the two users, as shown in the chat interface, replete with nearby locations pulled from Travonde‚Äôs database, and once they have indicated they are planning to meet up, we will provide them with transportation and residency options. And finally, at the end of their meet-up, we will solicit feedback from the users to further improve the workflow and identify any pain points that need improvement or streamlining. This product has the potential to disrupt the current location-based social media market by targeting the portion of the population who have much more disposable income, ultimately bringing them an opportunity they may have lacked before.
            </p>
            <embed src="project_materials/AscendTravondeSlideDeck.pdf" type="application/pdf" width="100%" height="550px" />
          </div>
		    </div>
      </div>
    </div>
  </div>
</body>

</html>
<script>
var slideIndex = 1;
showSlides(slideIndex);

function plusSlides(n) {
  showSlides(slideIndex += n);
}

function currentSlide(n) {
  showSlides(slideIndex = n);
}

function showSlides(n) {
  var i;
  var slides = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("slidesDot");
  var captionText = document.getElementsByClassName("slidesCaption");
  if (n > slides.length) {slideIndex = 1}
  if (n < 1) {slideIndex = slides.length}
  for (i = 0; i < slides.length; i++) {
      slides[i].style.display = "none";
  }
  for (i = 0; i < dots.length; i++) {
      dots[i].className = dots[i].className.replace(" active", "");
  }
  for (i = 0; i < captionText.length; i++) {
      captionText[i].style.display = "none";
  }
  captionText[slideIndex-1].style.display = "block";
  slides[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " active";
}
</script>

